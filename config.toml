# Graphiti MCP Server Configuration

[server]
host = "0.0.0.0"
port = 8080
log_level = "info"
# Enforce auth for write endpoints in production
require_auth = true
# Restrict CORS to known origins (adjust for your environment)
allowed_origins = ["http://localhost:8080"]
# tls = { cert_path = "/etc/graphiti/tls/server.crt", key_path = "/etc/graphiti/tls/server.key" }

# CozoDB Configuration (embedded graph database)
[cozo]
# Use sqlite/rocksdb in production for persistence
engine = "sqlite"
path = "./data/graphiti.db"
options = {}

# LLM Configuration - Choose one provider
# Note: Set the API key in environment variables (e.g., OPENAI_API_KEY, GROQ_API_KEY)

[llm]
# LLM is not actually used in current implementation
# Only embeddings are needed for semantic search and memory storage
# Keeping minimal config to avoid errors
provider = "ollama"
model = "disabled"
api_key = ""

[llm.openai]
base_url = "https://api.openai.com/v1"
model = "gpt-4-turbo-preview"
timeout_secs = 60
max_retries = 3
rate_limit = 60

[llm.ollama]
base_url = "http://localhost:11434"
model = "llama3.1:8b"
timeout_secs = 120
max_retries = 3
rate_limit = 120
keep_alive_secs = 600

[llm.ollama.options]
temperature = 0.7
top_p = 1.0
top_k = 40
num_predict = 1000
num_ctx = 4096

[llm.groq]
base_url = "https://api.groq.com/openai/v1"
model = "llama-3.1-8b-instant"
timeout_secs = 30
max_retries = 3
rate_limit = 30

[llm.huggingface]
base_url = "https://api-inference.huggingface.co"
model = "microsoft/DialoGPT-medium"
timeout_secs = 60
max_retries = 3
rate_limit = 60

# Embedder Configuration - Choose one provider
# Note: Set API keys in environment variables for cloud providers

[embedder]
# 使用 embed_anything（Candle 后端）+ 本地缓存的 HF 模型以获得更高语义质量（完全本地、离线可用）
provider = "embed_anything"
model = "google/embeddinggemma-300m"
dimension = 768
batch_size = 16
timeout = 120
api_key = ""
device = "auto"
max_length = 8192
# 不写死模型目录，推荐通过环境变量 EMBEDDING_MODEL_DIR 指向实际路径
# cache_dir = "./models/embeddinggemma-300m"

[embedder.openai]
model = "text-embedding-3-small"
dimension = 1536
batch_size = 100
timeout_secs = 30

[embedder.voyage]
model = "voyage-2"
dimension = 1024
batch_size = 100
timeout_secs = 30

[embedder.cohere]
model = "embed-english-v3.0"
dimension = 1024
batch_size = 96
timeout_secs = 30

[embedder.local]
# Local SentenceTransformers server (free)
base_url = "http://localhost:8000"
model = "sentence-transformers/all-MiniLM-L6-v2"
dimension = 384
batch_size = 32
timeout_secs = 60

[embedder.ollama]
# 已不使用（保留段落避免破坏反序列化，可忽略）
base_url = ""
model = ""
dimension = 0
batch_size = 0
timeout_secs = 0

[graphiti]
name = "default"
enable_deduplication = true
min_entity_confidence = 0.7
min_relationship_confidence = 0.6
max_context_window = 4000
generate_embeddings = true

[storage]
search_index_path = "./data/search"
vector_index_path = "./data/vectors"
