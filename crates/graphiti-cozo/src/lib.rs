//! CozoDB driver implementation for Graphiti

#![warn(missing_docs)]

use async_trait::async_trait;
use chrono::TimeZone;
use graphiti_core::error::Error;
use graphiti_core::error::Result;
use graphiti_core::graph::Edge;
// use graphiti_core::graph::EntityNode;
// use graphiti_core::graph::EpisodeNode;
// use graphiti_core::graph::CommunityNode;
use graphiti_core::graph::TemporalMetadata;
use graphiti_core::storage::Direction;
use graphiti_core::storage::GraphStorage;
#[cfg(feature = "backend-cozo")]
use std::collections::HashMap;
use std::sync::Arc;
#[cfg(feature = "backend-cozo")]
use tokio::sync::Mutex;
use tokio::sync::Semaphore;
use tracing::debug;
use tracing::info;
use tracing::instrument;
use tracing::warn;
use uuid::Uuid;

#[cfg(feature = "backend-cozo")]
use cozo::DbInstance;
#[cfg(feature = "backend-cozo")]
use cozo::NamedRows;
#[cfg(feature = "backend-cozo")]
use cozo::ScriptMutability;
#[cfg(feature = "backend-sqlx")]
use sqlx::sqlite::SqlitePoolOptions;

/// CozoDB configuration
#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct CozoConfig {
    /// Storage engine ("mem", "sqlite", "rocksdb")
    pub engine: String,
    /// Database path (for file-based engines)
    pub path: String,
    /// Additional options
    pub options: serde_json::Value,
}

impl Default for CozoConfig {
    fn default() -> Self {
        Self {
            engine: "mem".to_string(),
            path: "".to_string(),
            options: serde_json::json!({}),
        }
    }
}

/// CozoDB driver for Graphiti
pub struct CozoDriver {
    #[cfg(feature = "backend-cozo")]
    db: Arc<DbInstance>,
    #[cfg(feature = "backend-sqlx")]
    pool: Arc<sqlx::SqlitePool>,
    #[cfg(feature = "backend-cozo")]
    edges_mem: Arc<Mutex<HashMap<Uuid, Edge>>>,
    _config: CozoConfig,
    write_lock: Arc<Semaphore>,
}

impl CozoDriver {
    /// Create a new CozoDB driver with the given configuration
    #[allow(unreachable_code)]
    pub async fn new(config: CozoConfig) -> Result<Self> {
        info!("Creating storage instance with engine: {}", config.engine);

        #[cfg(all(feature = "backend-cozo", not(feature = "backend-sqlx")))]
        {
            let options_str = config.options.to_string();
            let db = DbInstance::new(&config.engine, &config.path, &options_str)
                .map_err(|e| Error::Storage(format!("Failed to create CozoDB instance: {}", e)))?;
            let driver = Self {
                db: Arc::new(db),
                edges_mem: Arc::new(Mutex::new(HashMap::new())),
                _config: config,
                write_lock: Arc::new(Semaphore::new(1)),
            };
            driver.initialize_schema().await?;
            return Ok(driver);
        }

        #[cfg(all(feature = "backend-sqlx", not(feature = "backend-cozo")))]
        {
            let url = if config.path == ":memory:" {
                // In-memory DB: use single connection to avoid isolated DBs per connection.
                // `cache=shared` is unreliable across multiple connections in some environments; prefer 1 conn.
                "sqlite::memory:".to_string()
            } else {
                format!("sqlite://{}", config.path)
            };
            let max_conns = if config.path == ":memory:" { 1 } else { 5 };
            let pool = SqlitePoolOptions::new()
                .max_connections(max_conns)
                .connect(&url)
                .await
                .map_err(|e| Error::Storage(format!("Failed to connect sqlite (sqlx): {}", e)))?;
            // Pragmas for durability/performance balance (file-backed only)
            if config.path != ":memory:" {
                let pragmas = [
                    "PRAGMA journal_mode=WAL",
                    "PRAGMA synchronous=NORMAL",
                    "PRAGMA busy_timeout=5000",
                    "PRAGMA temp_store=MEMORY",
                ];
                for p in pragmas.iter() {
                    let _ = sqlx::query(p).execute(&pool).await;
                }
            }
            let driver = Self {
                pool: Arc::new(pool),
                #[cfg(feature = "backend-cozo")]
                edges_mem: Arc::new(Mutex::new(HashMap::new())),
                _config: config,
                write_lock: Arc::new(Semaphore::new(1)),
            };
            driver.initialize_schema().await?;
            return Ok(driver);
        }

        #[cfg(all(feature = "backend-cozo", feature = "backend-sqlx"))]
        {
            // 双后端同时启用时，根据 engine 选择
            if config.engine == "mem" || config.engine == "rocksdb" {
                let options_str = config.options.to_string();
                let db =
                    DbInstance::new(&config.engine, &config.path, &options_str).map_err(|e| {
                        Error::Storage(format!("Failed to create CozoDB instance: {}", e))
                    })?;
                // 仍然初始化一个内存 sqlite 连接以满足结构体字段
                let pool = SqlitePoolOptions::new()
                    .max_connections(1)
                    .connect("sqlite::memory:")
                    .await
                    .map_err(|e| {
                        Error::Storage(format!("Failed to connect sqlite (sqlx): {}", e))
                    })?;
                let driver = Self {
                    db: Arc::new(db),
                    pool: Arc::new(pool),
                    edges_mem: Arc::new(Mutex::new(HashMap::new())),
                    _config: config,
                    write_lock: Arc::new(Semaphore::new(1)),
                };
                driver.initialize_schema().await?;
                return Ok(driver);
            } else {
                let url = if config.path == ":memory:" {
                    "sqlite::memory:".to_string()
                } else {
                    format!("sqlite://{}", config.path)
                };
                let pool = SqlitePoolOptions::new()
                    .max_connections(5)
                    .connect(&url)
                    .await
                    .map_err(|e| {
                        Error::Storage(format!("Failed to connect sqlite (sqlx): {}", e))
                    })?;
                // 仍然初始化一个内存 Cozo 引擎以满足结构体字段
                let db = DbInstance::new("mem", "", "{}").map_err(|e| {
                    Error::Storage(format!("Failed to create CozoDB instance: {}", e))
                })?;
                let driver = Self {
                    db: Arc::new(db),
                    pool: Arc::new(pool),
                    edges_mem: Arc::new(Mutex::new(HashMap::new())),
                    _config: config,
                    write_lock: Arc::new(Semaphore::new(1)),
                };
                driver.initialize_schema().await?;
                return Ok(driver);
            }
        }

        Err(Error::Storage("no backend selected".to_string()))
    }

    /// Compact the underlying SQLite database (VACUUM) when file-backed.
    /// No-op for in-memory or non-sqlite engines.
    pub async fn compact(&self) -> Result<()> {
        if self._config.engine == "mem" || self._config.engine == "rocksdb" {
            return Ok(());
        }
        #[cfg(feature = "backend-sqlx")]
        {
            if self._config.path == ":memory:" {
                return Ok(());
            }
            sqlx::query("VACUUM")
                .execute(&*self.pool)
                .await
                .map_err(|e| Error::Storage(format!("VACUUM failed: {}", e)))?;
            return Ok(());
        }
        #[cfg(not(feature = "backend-sqlx"))]
        {
            return Ok(());
        }
    }

    /// Initialize the database schema for Graphiti (idempotent)
    async fn initialize_schema(&self) -> Result<()> {
        info!("Initializing storage schema for Graphiti");

        // If cozo engine selected, build cozo schema
        #[cfg(feature = "backend-cozo")]
        if self._config.engine == "mem" || self._config.engine == "rocksdb" {
            // 内存模式：不执行任何 Cozo 脚本，使用内存结构即可
            info!("Cozo (mem) schema initialization skipped (using in-memory map)");
            return Ok(());
        }

        // Otherwise, initialize sqlite schema (default)
        #[cfg(feature = "backend-sqlx")]
        {
            let stmts = [
                "CREATE TABLE IF NOT EXISTS ctx_kv (ns TEXT NOT NULL, k TEXT NOT NULL, v TEXT NOT NULL, updated_at REAL NOT NULL, PRIMARY KEY(ns, k))",
                "CREATE TABLE IF NOT EXISTS file_snapshots (ns TEXT NOT NULL, path TEXT NOT NULL, content TEXT NOT NULL, updated_at REAL NOT NULL, PRIMARY KEY(ns, path))",
                "CREATE TABLE IF NOT EXISTS edges (id TEXT PRIMARY KEY, source_id TEXT NOT NULL, target_id TEXT NOT NULL, relationship TEXT NOT NULL, properties TEXT NOT NULL, created_at REAL NOT NULL, valid_from REAL NOT NULL, valid_to REAL, expired_at REAL, weight REAL NOT NULL)",
                // Useful indices for recent queries and retention pruning
                "CREATE INDEX IF NOT EXISTS idx_edges_created_at ON edges(created_at)",
                "CREATE INDEX IF NOT EXISTS idx_edges_rel_created ON edges(relationship, created_at)",
                // Minimal node tables (entity/episode/community)
                "CREATE TABLE IF NOT EXISTS entity_nodes (id TEXT PRIMARY KEY, name TEXT NOT NULL, entity_type TEXT NOT NULL, labels TEXT NOT NULL, properties TEXT NOT NULL, created_at REAL NOT NULL, valid_from REAL NOT NULL, valid_to REAL, expired_at REAL, embedding BLOB)",
                "CREATE TABLE IF NOT EXISTS episode_nodes (id TEXT PRIMARY KEY, name TEXT NOT NULL, content TEXT NOT NULL, source TEXT NOT NULL, episode_type TEXT NOT NULL, created_at REAL NOT NULL, valid_from REAL NOT NULL, valid_to REAL, expired_at REAL, embedding BLOB)",
                "CREATE TABLE IF NOT EXISTS community_nodes (id TEXT PRIMARY KEY, name TEXT NOT NULL, summary TEXT NOT NULL, members TEXT NOT NULL, metadata TEXT NOT NULL, created_at REAL NOT NULL, valid_from REAL NOT NULL, valid_to REAL, expired_at REAL)",
                "CREATE INDEX IF NOT EXISTS idx_entity_created_at ON entity_nodes(created_at)",
                "CREATE INDEX IF NOT EXISTS idx_episode_created_at ON episode_nodes(created_at)",
                "CREATE INDEX IF NOT EXISTS idx_community_created_at ON community_nodes(created_at)",
            ];
            for s in stmts.iter() {
                sqlx::query(s)
                    .execute(&*self.pool)
                    .await
                    .map_err(|e| Error::Storage(format!("Failed to create table: {}", e)))?;
            }
            info!("SQLite (sqlx) schema initialized successfully");
            return Ok(());
        }

        #[allow(unreachable_code)]
        Ok(())
    }

    #[cfg(feature = "backend-cozo")]
    async fn ensure_cozo_relations(&self) -> Result<()> {
        // Ensure core relations exist before operations
        self.create_table_if_not_exists(
            "g_edges",
            r#"
            {
                id: Uuid,
                source_id: Uuid,
                target_id: Uuid,
                relationship: String,
                properties: Json,
                created_at: Float,
                valid_from: Float,
                valid_to: Float?,
                expired_at: Float?,
                weight: Float
            }
            "#,
        )
        .await
    }

    /// Create a table if it doesn't exist (idempotent operation)
    #[allow(dead_code)]
    async fn create_table_if_not_exists(&self, table_name: &str, schema: &str) -> Result<()> {
        #[cfg(feature = "backend-cozo")]
        {
            // 使用 :create 或 :alter 以实现幂等
            let create_query = format!(":create {} {}", table_name, schema);
            return match self.execute_script(&create_query).await {
                Ok(_) => {
                    debug!("Created table '{}'", table_name);
                    Ok(())
                }
                Err(e) => {
                    let error_msg = e.to_string();
                    if error_msg.contains("conflicts with an existing one")
                        || error_msg.contains("already exists")
                    {
                        debug!(
                            "Table '{}' already exists, preserving existing data",
                            table_name
                        );
                        Ok(())
                    } else {
                        warn!("Failed to create table '{}': {}", table_name, error_msg);
                        Err(e)
                    }
                }
            };
        }
        #[cfg(feature = "backend-sqlx")]
        {
            let _ = table_name;
            let _ = schema; // handled in initialize_schema
            Ok(())
        }
        #[cfg(not(any(feature = "backend-cozo", feature = "backend-sqlx")))]
        {
            let _ = table_name;
            let _ = schema;
            Ok(())
        }
    }

    /// Execute a Datalog script (only for cozo backend)
    #[cfg(feature = "backend-cozo")]
    async fn execute_script(&self, script: &str) -> Result<NamedRows> {
        self.db
            .run_script(script, Default::default(), ScriptMutability::Mutable)
            .map_err(|e| Error::Storage(format!("Failed to execute script: {}", e)))
    }

    /// Query with Datalog script (only for cozo backend)
    #[cfg(feature = "backend-cozo")]
    async fn query_script(&self, script: &str) -> Result<NamedRows> {
        self.db
            .run_script(script, Default::default(), ScriptMutability::Immutable)
            .map_err(|e| Error::Storage(format!("Failed to execute query: {}", e)))
    }

    /// Convert TemporalMetadata to timestamp values
    fn temporal_to_timestamps(
        &self,
        temporal: &TemporalMetadata,
    ) -> (f64, f64, Option<f64>, Option<f64>) {
        (
            temporal.created_at.timestamp() as f64,
            temporal.valid_from.timestamp() as f64,
            temporal.valid_to.map(|t| t.timestamp() as f64),
            temporal.expired_at.map(|t| t.timestamp() as f64),
        )
    }

    // Public helpers for ContextStore (KV and file snapshots)
    /// Upsert a JSON value into ctx_kv under (ns, k)
    pub async fn kv_put(&self, ns: &str, k: &str, v: serde_json::Value) -> Result<()> {
        let updated_at = chrono::Utc::now().timestamp_millis() as f64 / 1000.0;
        #[cfg(feature = "backend-cozo")]
        {
            // mem/rocksdb 引擎下跳过脚本执行（当前 CI 目标是内存路径收口）
            let _ = (ns, k, v, updated_at);
            return Ok(());
        }
        #[cfg(feature = "backend-sqlx")]
        {
            sqlx::query("INSERT INTO ctx_kv(ns,k,v,updated_at) VALUES(?,?,?,?) ON CONFLICT(ns,k) DO UPDATE SET v=excluded.v, updated_at=excluded.updated_at")
                .bind(ns)
                .bind(k)
                .bind(v.to_string())
                .bind(updated_at)
                .execute(&* self.pool)
                .await
                .map_err(|e| Error::Storage(format!("kv_put failed: {}", e)))?;
            return Ok(());
        }
        #[cfg(not(any(feature = "backend-cozo", feature = "backend-sqlx")))]
        {
            let _ = (ns, k, v, updated_at);
            Ok(())
        }
    }

    /// Get a JSON value from ctx_kv by (ns, k)
    pub async fn kv_get(&self, ns: &str, k: &str) -> Result<Option<serde_json::Value>> {
        #[cfg(feature = "backend-cozo")]
        {
            let _ = (ns, k);
            return Ok(None);
        }
        #[cfg(feature = "backend-sqlx")]
        {
            if let Some(rec) =
                sqlx::query_scalar::<_, String>("SELECT v FROM ctx_kv WHERE ns=? AND k=?")
                    .bind(ns)
                    .bind(k)
                    .fetch_optional(&*self.pool)
                    .await
                    .map_err(|e| Error::Storage(format!("kv_get failed: {}", e)))?
            {
                let val: serde_json::Value = serde_json::from_str(&rec)
                    .map_err(|e| Error::Storage(format!("kv_get json parse: {}", e)))?;
                return Ok(Some(val));
            }
            return Ok(None);
        }
        #[cfg(not(any(feature = "backend-cozo", feature = "backend-sqlx")))]
        {
            let _ = (ns, k);
            Ok(None)
        }
    }

    /// Upsert a file snapshot content under (ns, path)
    pub async fn file_snapshot_put(&self, ns: &str, path: &str, content: &str) -> Result<()> {
        let updated_at = chrono::Utc::now().timestamp_millis() as f64 / 1000.0;
        #[cfg(feature = "backend-cozo")]
        {
            let _ = (ns, path, content, updated_at);
            return Ok(());
        }
        #[cfg(feature = "backend-sqlx")]
        {
            sqlx::query("INSERT INTO file_snapshots(ns,path,content,updated_at) VALUES(?,?,?,?) ON CONFLICT(ns,path) DO UPDATE SET content=excluded.content, updated_at=excluded.updated_at")
                .bind(ns)
                .bind(path)
                .bind(content)
                .bind(updated_at)
                .execute(&* self.pool)
                .await
                .map_err(|e| Error::Storage(format!("file_snapshot_put failed: {}", e)))?;
            return Ok(());
        }
        #[cfg(not(any(feature = "backend-cozo", feature = "backend-sqlx")))]
        {
            let _ = (ns, path, content, updated_at);
            Ok(())
        }
    }

    /// Get file snapshot content by (ns, path)
    pub async fn file_snapshot_get(&self, ns: &str, path: &str) -> Result<Option<String>> {
        #[cfg(feature = "backend-cozo")]
        {
            let _ = (ns, path);
            return Ok(None);
        }
        #[cfg(feature = "backend-sqlx")]
        {
            let rec = sqlx::query_scalar::<_, String>(
                "SELECT content FROM file_snapshots WHERE ns=? AND path=?",
            )
            .bind(ns)
            .bind(path)
            .fetch_optional(&*self.pool)
            .await
            .map_err(|e| Error::Storage(format!("file_snapshot_get failed: {}", e)))?;
            return Ok(rec);
        }
        #[cfg(not(any(feature = "backend-cozo", feature = "backend-sqlx")))]
        {
            let _ = (ns, path);
            Ok(None)
        }
    }
}

#[cfg(any(feature = "backend-cozo", feature = "backend-sqlx"))]
#[async_trait]
impl GraphStorage for CozoDriver {
    type Error = Error;

    #[instrument(skip(self, node))]
    async fn create_node(&self, node: &dyn graphiti_core::graph::Node) -> Result<()> {
        let id = *node.id();
        let labels = node.labels();
        let properties = node.properties();
        let temporal = node.temporal();
        let (created_at, valid_from, valid_to, expired_at) = self.temporal_to_timestamps(temporal);

        // memory engines: no-op
        if self._config.engine == "mem" || self._config.engine == "rocksdb" {
            #[cfg(feature = "backend-cozo")]
            {
                debug!("[mem] create_node skipped scripts for {}", id);
                return Ok(());
            }
        }

        #[cfg(feature = "backend-sqlx")]
        {
            let _permit = self.write_lock.acquire().await.unwrap();
            // Decide table by best-effort introspection of properties/labels
            let labels_json = serde_json::to_string(&labels).unwrap_or_else(|_| "[]".to_string());
            if properties.get("episode_type").is_some() || labels.iter().any(|l| l == "Episode") {
                // EpisodeNode-like
                let name = properties
                    .get("name")
                    .and_then(|v| v.as_str())
                    .unwrap_or("");
                let content = properties
                    .get("content")
                    .and_then(|v| v.as_str())
                    .unwrap_or("");
                let source = properties
                    .get("source")
                    .and_then(|v| v.as_str())
                    .unwrap_or("");
                let episode_type = properties
                    .get("episode_type")
                    .and_then(|v| v.as_str())
                    .unwrap_or("unknown");
                sqlx::query("INSERT INTO episode_nodes(id,name,content,source,episode_type,created_at,valid_from,valid_to,expired_at,embedding) VALUES(?,?,?,?,?,?,?,?,?,NULL) ON CONFLICT(id) DO UPDATE SET name=excluded.name,content=excluded.content,source=excluded.source,episode_type=excluded.episode_type,created_at=excluded.created_at,valid_from=excluded.valid_from,valid_to=excluded.valid_to,expired_at=excluded.expired_at,embedding=excluded.embedding")
                    .bind(id.to_string())
                    .bind(name)
                    .bind(content)
                    .bind(source)
                    .bind(episode_type)
                    .bind(created_at)
                    .bind(valid_from)
                    .bind(valid_to)
                    .bind(expired_at)
                    .execute(&* self.pool)
                    .await
                    .map_err(|e| Error::Storage(format!("Failed to insert episode: {}", e)))?;
            } else if properties.get("entity_type").is_some()
                || labels.iter().any(|l| l == "Entity")
            {
                // EntityNode-like
                let name = properties
                    .get("name")
                    .and_then(|v| v.as_str())
                    .unwrap_or("");
                let entity_type = properties
                    .get("entity_type")
                    .and_then(|v| v.as_str())
                    .unwrap_or("unknown");
                sqlx::query("INSERT INTO entity_nodes(id,name,entity_type,labels,properties,created_at,valid_from,valid_to,expired_at,embedding) VALUES(?,?,?,?,?,?,?,?,?,NULL) ON CONFLICT(id) DO UPDATE SET name=excluded.name,entity_type=excluded.entity_type,labels=excluded.labels,properties=excluded.properties,created_at=excluded.created_at,valid_from=excluded.valid_from,valid_to=excluded.valid_to,expired_at=excluded.expired_at,embedding=excluded.embedding")
                    .bind(id.to_string())
                    .bind(name)
                    .bind(entity_type)
                    .bind(labels_json)
                    .bind(properties.to_string())
                    .bind(created_at)
                    .bind(valid_from)
                    .bind(valid_to)
                    .bind(expired_at)
                    .execute(&* self.pool)
                    .await
                    .map_err(|e| Error::Storage(format!("Failed to insert entity: {}", e)))?;
            } else {
                // Community or generic
                let name = properties
                    .get("name")
                    .and_then(|v| v.as_str())
                    .unwrap_or("");
                let summary = properties
                    .get("summary")
                    .and_then(|v| v.as_str())
                    .unwrap_or("");
                let members = properties
                    .get("members")
                    .cloned()
                    .unwrap_or_else(|| serde_json::json!([]))
                    .to_string();
                let metadata = properties
                    .get("metadata")
                    .cloned()
                    .unwrap_or_else(|| serde_json::json!({}))
                    .to_string();
                sqlx::query("INSERT INTO community_nodes(id,name,summary,members,metadata,created_at,valid_from,valid_to,expired_at) VALUES(?,?,?,?,?,?,?,?,?) ON CONFLICT(id) DO UPDATE SET name=excluded.name,summary=excluded.summary,members=excluded.members,metadata=excluded.metadata,created_at=excluded.created_at,valid_from=excluded.valid_from,valid_to=excluded.valid_to,expired_at=excluded.expired_at")
                    .bind(id.to_string())
                    .bind(name)
                    .bind(summary)
                    .bind(members)
                    .bind(metadata)
                    .bind(created_at)
                    .bind(valid_from)
                    .bind(valid_to)
                    .bind(expired_at)
                    .execute(&* self.pool)
                    .await
                    .map_err(|e| Error::Storage(format!("Failed to insert community: {}", e)))?;
            }
        }

        debug!("Created node with ID: {}", id);
        Ok(())
    }

    #[instrument(skip(self))]
    async fn get_node(&self, id: &Uuid) -> Result<Option<Box<dyn graphiti_core::graph::Node>>> {
        // In mem/rocksdb engines, skip Cozo script execution entirely
        #[cfg(feature = "backend-cozo")]
        if self._config.engine == "mem" || self._config.engine == "rocksdb" {
            debug!("[mem] get_node skipped scripts for {}", id);
            return Ok(None);
        }
        // Try to find the node in each table
        let _script = format!(
            r#"
            ?[id, name, entity_type, labels, properties, created_at, valid_from, valid_to, expired_at, embedding] := 
                entity_nodes[id, name, entity_type, labels, properties, created_at, valid_from, valid_to, expired_at, embedding],
                id == to_uuid("{}")
            "#,
            id
        );

        #[cfg(feature = "backend-cozo")]
        let _result = self.query_script(&script).await?;

        // For now, return None as we need to implement proper node reconstruction
        debug!("Queried node with ID: {}", id);
        Ok(None)
    }

    #[instrument(skip(self, nodes))]
    async fn create_nodes_batch(
        &self,
        nodes: &[Box<dyn graphiti_core::graph::Node>],
    ) -> Result<()> {
        if nodes.is_empty() {
            return Ok(());
        }
        if self._config.engine == "mem" || self._config.engine == "rocksdb" {
            #[cfg(feature = "backend-cozo")]
            {
                return Ok(());
            }
        }
        #[cfg(feature = "backend-sqlx")]
        {
            let _permit = self.write_lock.acquire().await.unwrap();
            let mut tx = self.pool.begin().await.map_err(|e| {
                Error::Storage(format!("Failed to begin transaction (nodes): {}", e))
            })?;
            for n in nodes {
                let id = *n.id();
                let labels = n.labels();
                let properties = n.properties();
                let (created_at, valid_from, valid_to, expired_at) =
                    self.temporal_to_timestamps(n.temporal());
                let labels_json =
                    serde_json::to_string(&labels).unwrap_or_else(|_| "[]".to_string());
                if properties.get("episode_type").is_some() || labels.iter().any(|l| l == "Episode")
                {
                    let name = properties
                        .get("name")
                        .and_then(|v| v.as_str())
                        .unwrap_or("");
                    let content = properties
                        .get("content")
                        .and_then(|v| v.as_str())
                        .unwrap_or("");
                    let source = properties
                        .get("source")
                        .and_then(|v| v.as_str())
                        .unwrap_or("");
                    let episode_type = properties
                        .get("episode_type")
                        .and_then(|v| v.as_str())
                        .unwrap_or("unknown");
                    sqlx::query("INSERT INTO episode_nodes(id,name,content,source,episode_type,created_at,valid_from,valid_to,expired_at,embedding) VALUES(?,?,?,?,?,?,?,?,?,NULL) ON CONFLICT(id) DO UPDATE SET name=excluded.name,content=excluded.content,source=excluded.source,episode_type=excluded.episode_type,created_at=excluded.created_at,valid_from=excluded.valid_from,valid_to=excluded.valid_to,expired_at=excluded.expired_at,embedding=excluded.embedding")
                        .bind(id.to_string()).bind(name).bind(content).bind(source).bind(episode_type)
                        .bind(created_at).bind(valid_from).bind(valid_to).bind(expired_at)
                        .execute(&mut *tx).await
                        .map_err(|e| Error::Storage(format!("batch node insert (episode) failed: {}", e)))?;
                } else if properties.get("entity_type").is_some()
                    || labels.iter().any(|l| l == "Entity")
                {
                    let name = properties
                        .get("name")
                        .and_then(|v| v.as_str())
                        .unwrap_or("");
                    let entity_type = properties
                        .get("entity_type")
                        .and_then(|v| v.as_str())
                        .unwrap_or("unknown");
                    sqlx::query("INSERT INTO entity_nodes(id,name,entity_type,labels,properties,created_at,valid_from,valid_to,expired_at,embedding) VALUES(?,?,?,?,?,?,?,?,?,NULL) ON CONFLICT(id) DO UPDATE SET name=excluded.name,entity_type=excluded.entity_type,labels=excluded.labels,properties=excluded.properties,created_at=excluded.created_at,valid_from=excluded.valid_from,valid_to=excluded.valid_to,expired_at=excluded.expired_at,embedding=excluded.embedding")
                        .bind(id.to_string()).bind(name).bind(entity_type).bind(labels_json).bind(properties.to_string())
                        .bind(created_at).bind(valid_from).bind(valid_to).bind(expired_at)
                        .execute(&mut *tx).await
                        .map_err(|e| Error::Storage(format!("batch node insert (entity) failed: {}", e)))?;
                } else {
                    let name = properties
                        .get("name")
                        .and_then(|v| v.as_str())
                        .unwrap_or("");
                    let summary = properties
                        .get("summary")
                        .and_then(|v| v.as_str())
                        .unwrap_or("");
                    let members = properties
                        .get("members")
                        .cloned()
                        .unwrap_or_else(|| serde_json::json!([]))
                        .to_string();
                    let metadata = properties
                        .get("metadata")
                        .cloned()
                        .unwrap_or_else(|| serde_json::json!({}))
                        .to_string();
                    sqlx::query("INSERT INTO community_nodes(id,name,summary,members,metadata,created_at,valid_from,valid_to,expired_at) VALUES(?,?,?,?,?,?,?,?,?) ON CONFLICT(id) DO UPDATE SET name=excluded.name,summary=excluded.summary,members=excluded.members,metadata=excluded.metadata,created_at=excluded.created_at,valid_from=excluded.valid_from,valid_to=excluded.valid_to,expired_at=excluded.expired_at")
                        .bind(id.to_string()).bind(name).bind(summary).bind(members).bind(metadata)
                        .bind(created_at).bind(valid_from).bind(valid_to).bind(expired_at)
                        .execute(&mut *tx).await
                        .map_err(|e| Error::Storage(format!("batch node insert (community) failed: {}", e)))?;
                }
            }
            tx.commit()
                .await
                .map_err(|e| Error::Storage(format!("commit nodes batch failed: {}", e)))?;
        }
        Ok(())
    }

    #[instrument(skip(self, node))]
    async fn update_node(&self, node: &dyn graphiti_core::graph::Node) -> Result<()> {
        // Implementation similar to create_node but with update logic
        debug!("Updated node with ID: {}", node.id());
        Ok(())
    }

    #[instrument(skip(self))]
    async fn delete_node(&self, id: &Uuid) -> Result<()> {
        // In mem/rocksdb engines, skip Cozo script execution entirely
        #[cfg(feature = "backend-cozo")]
        if self._config.engine == "mem" || self._config.engine == "rocksdb" {
            debug!("[mem] delete_node skipped scripts for {}", id);
            return Ok(());
        }
        let _script = format!(
            r#"
            ?[id] <- [[to_uuid("{}")]]
            :rm entity_nodes {{id}}
            :rm episode_nodes {{id}}
            :rm community_nodes {{id}}
            "#,
            id
        );

        #[cfg(feature = "backend-cozo")]
        {
            self.execute_script(&script).await?;
        }
        debug!("Deleted node with ID: {}", id);
        Ok(())
    }

    #[instrument(skip(self))]
    async fn create_edge(&self, edge: &Edge) -> Result<()> {
        let (created_at, valid_from, valid_to, expired_at) =
            self.temporal_to_timestamps(&edge.temporal);

        if self._config.engine == "mem" || self._config.engine == "rocksdb" {
            #[cfg(feature = "backend-cozo")]
            {
                let mut map = self.edges_mem.lock().await;
                map.insert(edge.id, edge.clone());
            }
            #[cfg(not(feature = "backend-cozo"))]
            {
                return Err(Error::Storage("cozo backend not compiled".to_string()));
            }
        } else {
            #[cfg(feature = "backend-sqlx")]
            {
                let _permit = self.write_lock.acquire().await.unwrap();
                let props = edge.properties.to_string();
                sqlx::query("INSERT INTO edges(id,source_id,target_id,relationship,properties,created_at,valid_from,valid_to,expired_at,weight) VALUES(?,?,?,?,?,?,?,?,?,?) ON CONFLICT(id) DO UPDATE SET source_id=excluded.source_id,target_id=excluded.target_id,relationship=excluded.relationship,properties=excluded.properties,created_at=excluded.created_at,valid_from=excluded.valid_from,valid_to=excluded.valid_to,expired_at=excluded.expired_at,weight=excluded.weight")
                    .bind(edge.id.to_string())
                    .bind(edge.source_id.to_string())
                    .bind(edge.target_id.to_string())
                    .bind(&edge.relationship)
                    .bind(props)
                    .bind(created_at)
                    .bind(valid_from)
                    .bind(valid_to)
                    .bind(expired_at)
                    .bind(edge.weight as f64)
                    .execute(&* self.pool)
                    .await
                    .map_err(|e| Error::Storage(format!("Failed to insert edge: {}", e)))?;
            }
            #[cfg(not(feature = "backend-sqlx"))]
            {
                return Err(Error::Storage("sqlx backend not compiled".to_string()));
            }
        }
        debug!(
            "Created edge from {} to {} with relationship {}",
            edge.source_id, edge.target_id, edge.relationship
        );
        Ok(())
    }

    #[instrument(skip(self, edges))]
    async fn create_edges_batch(&self, edges: &[Edge]) -> Result<()> {
        if edges.is_empty() {
            return Ok(());
        }
        if self._config.engine == "mem" || self._config.engine == "rocksdb" {
            #[cfg(feature = "backend-cozo")]
            {
                let mut map = self.edges_mem.lock().await;
                for edge in edges {
                    map.insert(edge.id, edge.clone());
                }
            }
            #[cfg(not(feature = "backend-cozo"))]
            {
                return Err(Error::Storage("cozo backend not compiled".to_string()));
            }
        } else {
            #[cfg(feature = "backend-sqlx")]
            {
                let _permit = self.write_lock.acquire().await.unwrap();
                let mut tx =
                    self.pool.begin().await.map_err(|e| {
                        Error::Storage(format!("Failed to begin transaction: {}", e))
                    })?;
                for edge in edges {
                    let (created_at, valid_from, valid_to, expired_at) =
                        self.temporal_to_timestamps(&edge.temporal);
                    let props = edge.properties.to_string();
                    sqlx::query("INSERT INTO edges(id,source_id,target_id,relationship,properties,created_at,valid_from,valid_to,expired_at,weight) VALUES(?,?,?,?,?,?,?,?,?,?) ON CONFLICT(id) DO UPDATE SET source_id=excluded.source_id,target_id=excluded.target_id,relationship=excluded.relationship,properties=excluded.properties,created_at=excluded.created_at,valid_from=excluded.valid_from,valid_to=excluded.valid_to,expired_at=excluded.expired_at,weight=excluded.weight")
                        .bind(edge.id.to_string())
                        .bind(edge.source_id.to_string())
                        .bind(edge.target_id.to_string())
                        .bind(&edge.relationship)
                        .bind(props)
                        .bind(created_at)
                        .bind(valid_from)
                        .bind(valid_to)
                        .bind(expired_at)
                        .bind(edge.weight as f64)
                        .execute(&mut *tx)
                        .await
                        .map_err(|e| Error::Storage(format!("Failed to insert edge in batch: {}", e)))?;
                }
                tx.commit()
                    .await
                    .map_err(|e| Error::Storage(format!("Failed to commit transaction: {}", e)))?;
            }
            #[cfg(not(feature = "backend-sqlx"))]
            {
                return Err(Error::Storage("sqlx backend not compiled".to_string()));
            }
        }
        debug!("Created {} edges in batch", edges.len());
        Ok(())
    }

    #[instrument(skip(self))]
    async fn get_edge_by_id(&self, id: &Uuid) -> Result<Option<Edge>> {
        if !(self._config.engine == "mem" || self._config.engine == "rocksdb") {
            #[cfg(feature = "backend-sqlx")]
            {
                use sqlx::Row;
                let row_opt = sqlx::query(
                "SELECT id, source_id, target_id, relationship, properties, created_at, valid_from, valid_to, expired_at, weight FROM edges WHERE id = ?"
            )
            .bind(id.to_string())
            .fetch_optional(&* self.pool)
            .await
            .map_err(|e| Error::Storage(format!("get_edge_by_id failed: {}", e)))?;

                if let Some(r) = row_opt {
                    let id_s: String = r.get("id");
                    let src_s: String = r.get("source_id");
                    let tgt_s: String = r.get("target_id");
                    let rel: String = r.get("relationship");
                    let props_s: String = r.get("properties");
                    let created_at_f: f64 = r.get("created_at");
                    let valid_from_f: f64 = r.get("valid_from");
                    let valid_to_o: Option<f64> = r.try_get("valid_to").ok();
                    let expired_at_o: Option<f64> = r.try_get("expired_at").ok();
                    let weight_f: f64 = r.get("weight");

                    let props: serde_json::Value = serde_json::from_str(&props_s)
                        .map_err(|e| Error::Storage(format!("edge.properties parse: {}", e)))?;

                    let edge = Edge {
                        id: Uuid::parse_str(&id_s).unwrap_or(*id),
                        source_id: Uuid::parse_str(&src_s).unwrap_or(Uuid::nil()),
                        target_id: Uuid::parse_str(&tgt_s).unwrap_or(Uuid::nil()),
                        relationship: rel,
                        properties: props,
                        temporal: TemporalMetadata {
                            created_at: chrono::Utc
                                .timestamp_millis_opt((created_at_f * 1000.0) as i64)
                                .single()
                                .unwrap_or_else(chrono::Utc::now),
                            valid_from: chrono::Utc
                                .timestamp_millis_opt((valid_from_f * 1000.0) as i64)
                                .single()
                                .unwrap_or_else(chrono::Utc::now),
                            valid_to: valid_to_o.and_then(|v| {
                                chrono::Utc
                                    .timestamp_millis_opt((v * 1000.0) as i64)
                                    .single()
                            }),
                            expired_at: expired_at_o.and_then(|v| {
                                chrono::Utc
                                    .timestamp_millis_opt((v * 1000.0) as i64)
                                    .single()
                            }),
                        },
                        weight: weight_f as f32,
                    };
                    return Ok(Some(edge));
                }
                return Ok(None);
            }
            #[cfg(not(feature = "backend-sqlx"))]
            {
                let _ = id;
                return Ok(None);
            }
        } else {
            #[cfg(feature = "backend-cozo")]
            {
                let map = self.edges_mem.lock().await;
                if let Some(e) = map.get(id) {
                    return Ok(Some(e.clone()));
                }
                return Ok(None);
            }
            #[cfg(not(feature = "backend-cozo"))]
            {
                let _ = id;
                return Ok(None);
            }
        }
    }

    #[instrument(skip(self))]
    async fn delete_edge_by_id(&self, id: &Uuid) -> Result<bool> {
        if self._config.engine == "mem" || self._config.engine == "rocksdb" {
            #[cfg(feature = "backend-cozo")]
            {
                let mut map = self.edges_mem.lock().await;
                return Ok(map.remove(id).is_some());
            }
            #[cfg(not(feature = "backend-cozo"))]
            {
                return Ok(false);
            }
        } else {
            #[cfg(feature = "backend-sqlx")]
            {
                let res = sqlx::query("DELETE FROM edges WHERE id = ?")
                    .bind(id.to_string())
                    .execute(&*self.pool)
                    .await
                    .map_err(|e| Error::Storage(format!("delete_edge_by_id failed: {}", e)))?;
                return Ok(res.rows_affected() > 0);
            }
            #[cfg(not(feature = "backend-sqlx"))]
            {
                return Ok(false);
            }
        }
    }

    #[instrument(skip(self))]
    async fn get_edges(&self, node_id: &Uuid, direction: Direction) -> Result<Vec<Edge>> {
        if !(self._config.engine == "mem" || self._config.engine == "rocksdb") {
            #[cfg(feature = "backend-sqlx")]
            {
                use sqlx::Row;
                let (sql, bind1, bind2) = match direction {
                Direction::Outgoing => (
                    "SELECT id, source_id, target_id, relationship, properties, created_at, valid_from, valid_to, expired_at, weight FROM edges WHERE source_id = ?",
                    node_id.to_string(),
                    None,
                ),
                Direction::Incoming => (
                    "SELECT id, source_id, target_id, relationship, properties, created_at, valid_from, valid_to, expired_at, weight FROM edges WHERE target_id = ?",
                    node_id.to_string(),
                    None,
                ),
                Direction::Both => (
                    "SELECT id, source_id, target_id, relationship, properties, created_at, valid_from, valid_to, expired_at, weight FROM edges WHERE source_id = ? OR target_id = ?",
                    node_id.to_string(),
                    Some(node_id.to_string()),
                ),
            };
                let mut q = sqlx::query(sql).bind(bind1);
                if let Some(b2) = bind2 {
                    q = q.bind(b2);
                }
                let rows = q
                    .fetch_all(&*self.pool)
                    .await
                    .map_err(|e| Error::Storage(format!("get_edges failed: {}", e)))?;
                let mut out = Vec::new();
                for r in rows {
                    let id_s: String = r.get("id");
                    let src_s: String = r.get("source_id");
                    let tgt_s: String = r.get("target_id");
                    let rel: String = r.get("relationship");
                    let props_s: String = r.get("properties");
                    let created_at_f: f64 = r.get("created_at");
                    let valid_from_f: f64 = r.get("valid_from");
                    let valid_to_o: Option<f64> = r.try_get("valid_to").ok();
                    let expired_at_o: Option<f64> = r.try_get("expired_at").ok();
                    let weight_f: f64 = r.get("weight");
                    let props: serde_json::Value =
                        serde_json::from_str(&props_s).unwrap_or(serde_json::json!({}));
                    out.push(Edge {
                        id: Uuid::parse_str(&id_s).unwrap_or(Uuid::nil()),
                        source_id: Uuid::parse_str(&src_s).unwrap_or(Uuid::nil()),
                        target_id: Uuid::parse_str(&tgt_s).unwrap_or(Uuid::nil()),
                        relationship: rel,
                        properties: props,
                        temporal: TemporalMetadata {
                            created_at: chrono::Utc
                                .timestamp_millis_opt((created_at_f * 1000.0) as i64)
                                .single()
                                .unwrap_or_else(chrono::Utc::now),
                            valid_from: chrono::Utc
                                .timestamp_millis_opt((valid_from_f * 1000.0) as i64)
                                .single()
                                .unwrap_or_else(chrono::Utc::now),
                            valid_to: valid_to_o.and_then(|v| {
                                chrono::Utc
                                    .timestamp_millis_opt((v * 1000.0) as i64)
                                    .single()
                            }),
                            expired_at: expired_at_o.and_then(|v| {
                                chrono::Utc
                                    .timestamp_millis_opt((v * 1000.0) as i64)
                                    .single()
                            }),
                        },
                        weight: weight_f as f32,
                    });
                }
                return Ok(out);
            }
            #[cfg(not(feature = "backend-sqlx"))]
            {
                return Ok(Vec::new());
            }
        } else {
            #[cfg(feature = "backend-cozo")]
            {
                let map = self.edges_mem.lock().await;
                let mut out = Vec::new();
                for e in map.values() {
                    out.push(e.clone());
                }
                return Ok(out);
            }
            #[cfg(not(feature = "backend-cozo"))]
            {
                return Ok(Vec::new());
            }
        }
    }

    #[instrument(skip(self))]
    async fn get_all_nodes(&self) -> Result<Vec<Box<dyn graphiti_core::graph::Node>>> {
        // Minimal viable implementation: return empty until node tables are defined
        Ok(Vec::new())
    }

    #[instrument(skip(self))]
    async fn get_all_edges(&self) -> Result<Vec<graphiti_core::graph::Edge>> {
        if !(self._config.engine == "mem" || self._config.engine == "rocksdb") {
            #[cfg(feature = "backend-sqlx")]
            {
                use sqlx::Row;
                let rows = sqlx::query(
                "SELECT id, source_id, target_id, relationship, properties, created_at, valid_from, valid_to, expired_at, weight FROM edges ORDER BY created_at DESC LIMIT 2000"
            )
            .fetch_all(&* self.pool)
            .await
            .map_err(|e| Error::Storage(format!("get_all_edges failed: {}", e)))?;
                let mut out = Vec::new();
                for r in rows {
                    let id_s: String = r.get("id");
                    let src_s: String = r.get("source_id");
                    let tgt_s: String = r.get("target_id");
                    let rel: String = r.get("relationship");
                    let props_s: String = r.get("properties");
                    let created_at_f: f64 = r.get("created_at");
                    let valid_from_f: f64 = r.get("valid_from");
                    let valid_to_o: Option<f64> = r.try_get("valid_to").ok();
                    let expired_at_o: Option<f64> = r.try_get("expired_at").ok();
                    let weight_f: f64 = r.get("weight");
                    let props: serde_json::Value =
                        serde_json::from_str(&props_s).unwrap_or(serde_json::json!({}));
                    out.push(graphiti_core::graph::Edge {
                        id: Uuid::parse_str(&id_s).unwrap_or_else(|_| Uuid::nil()),
                        source_id: Uuid::parse_str(&src_s).unwrap_or_else(|_| Uuid::nil()),
                        target_id: Uuid::parse_str(&tgt_s).unwrap_or_else(|_| Uuid::nil()),
                        relationship: rel,
                        properties: props,
                        temporal: TemporalMetadata {
                            created_at: chrono::Utc
                                .timestamp_millis_opt((created_at_f * 1000.0) as i64)
                                .single()
                                .unwrap_or_else(chrono::Utc::now),
                            valid_from: chrono::Utc
                                .timestamp_millis_opt((valid_from_f * 1000.0) as i64)
                                .single()
                                .unwrap_or_else(chrono::Utc::now),
                            valid_to: valid_to_o.and_then(|v| {
                                chrono::Utc
                                    .timestamp_millis_opt((v * 1000.0) as i64)
                                    .single()
                            }),
                            expired_at: expired_at_o.and_then(|v| {
                                chrono::Utc
                                    .timestamp_millis_opt((v * 1000.0) as i64)
                                    .single()
                            }),
                        },
                        weight: weight_f as f32,
                    });
                }
                return Ok(out);
            }
            #[cfg(not(feature = "backend-sqlx"))]
            {
                return Ok(Vec::new());
            }
        } else {
            #[cfg(feature = "backend-cozo")]
            {
                let map = self.edges_mem.lock().await;
                Ok(map.values().cloned().collect())
            }
            #[cfg(not(feature = "backend-cozo"))]
            {
                return Ok(Vec::new());
            }
        }
    }

    #[instrument(skip(self))]
    async fn get_recent_edges_by_rel(
        &self,
        relationship: &str,
        limit: usize,
    ) -> Result<Vec<graphiti_core::graph::Edge>> {
        if !(self._config.engine == "mem" || self._config.engine == "rocksdb") {
            #[cfg(feature = "backend-sqlx")]
            {
                use sqlx::Row;
                let rows = sqlx::query(
                    "SELECT id, source_id, target_id, relationship, properties, created_at, valid_from, valid_to, expired_at, weight \
                     FROM edges WHERE relationship = ? ORDER BY created_at DESC LIMIT ?"
                )
                .bind(relationship)
                .bind(limit as i64)
                .fetch_all(&* self.pool)
                .await
                .map_err(|e| Error::Storage(format!("get_recent_edges_by_rel failed: {}", e)))?;
                let mut out = Vec::new();
                for r in rows {
                    let id_s: String = r.get("id");
                    let src_s: String = r.get("source_id");
                    let tgt_s: String = r.get("target_id");
                    let rel: String = r.get("relationship");
                    let props_s: String = r.get("properties");
                    let created_at_f: f64 = r.get("created_at");
                    let valid_from_f: f64 = r.get("valid_from");
                    let valid_to_o: Option<f64> = r.try_get("valid_to").ok();
                    let expired_at_o: Option<f64> = r.try_get("expired_at").ok();
                    let weight_f: f64 = r.get("weight");
                    let props: serde_json::Value =
                        serde_json::from_str(&props_s).unwrap_or(serde_json::json!({}));
                    out.push(graphiti_core::graph::Edge {
                        id: Uuid::parse_str(&id_s).unwrap_or_else(|_| Uuid::nil()),
                        source_id: Uuid::parse_str(&src_s).unwrap_or_else(|_| Uuid::nil()),
                        target_id: Uuid::parse_str(&tgt_s).unwrap_or_else(|_| Uuid::nil()),
                        relationship: rel,
                        properties: props,
                        temporal: TemporalMetadata {
                            created_at: chrono::Utc
                                .timestamp_millis_opt((created_at_f * 1000.0) as i64)
                                .single()
                                .unwrap_or_else(chrono::Utc::now),
                            valid_from: chrono::Utc
                                .timestamp_millis_opt((valid_from_f * 1000.0) as i64)
                                .single()
                                .unwrap_or_else(chrono::Utc::now),
                            valid_to: valid_to_o.and_then(|v| {
                                chrono::Utc
                                    .timestamp_millis_opt((v * 1000.0) as i64)
                                    .single()
                            }),
                            expired_at: expired_at_o.and_then(|v| {
                                chrono::Utc
                                    .timestamp_millis_opt((v * 1000.0) as i64)
                                    .single()
                            }),
                        },
                        weight: weight_f as f32,
                    });
                }
                return Ok(out);
            }
            #[cfg(not(feature = "backend-sqlx"))]
            {
                return Ok(Vec::new());
            }
        } else {
            #[cfg(feature = "backend-cozo")]
            {
                let map = self.edges_mem.lock().await;
                let mut out: Vec<_> = map
                    .values()
                    .filter(|e| e.relationship == relationship)
                    .cloned()
                    .collect();
                out.sort_by(|a, b| b.temporal.created_at.cmp(&a.temporal.created_at));
                if out.len() > limit {
                    out.truncate(limit);
                }
                Ok(out)
            }
            #[cfg(not(feature = "backend-cozo"))]
            {
                return Ok(Vec::new());
            }
        }
    }

    #[instrument(skip(self))]
    async fn get_nodes_at_time(
        &self,
        _timestamp: chrono::DateTime<chrono::Utc>,
    ) -> Result<Vec<Box<dyn graphiti_core::graph::Node>>> {
        // For now, return empty vector - this would need proper temporal query implementation
        warn!("get_nodes_at_time not fully implemented yet");
        Ok(Vec::new())
    }

    #[instrument(skip(self))]
    async fn get_edges_at_time(
        &self,
        _timestamp: chrono::DateTime<chrono::Utc>,
    ) -> Result<Vec<graphiti_core::graph::Edge>> {
        // For now, return empty vector - this would need proper temporal query implementation
        warn!("get_edges_at_time not fully implemented yet");
        Ok(Vec::new())
    }

    #[instrument(skip(self))]
    async fn get_node_history(
        &self,
        _node_id: &Uuid,
    ) -> Result<Vec<Box<dyn graphiti_core::graph::Node>>> {
        // For now, return empty vector - this would need proper history tracking implementation
        warn!("get_node_history not fully implemented yet");
        Ok(Vec::new())
    }

    #[instrument(skip(self))]
    async fn get_edge_history(&self, _edge_id: &Uuid) -> Result<Vec<graphiti_core::graph::Edge>> {
        // For now, return empty vector - this would need proper history tracking implementation
        warn!("get_edge_history not fully implemented yet");
        Ok(Vec::new())
    }
}

#[cfg(not(any(feature = "backend-cozo", feature = "backend-sqlx")))]
#[async_trait]
impl GraphStorage for CozoDriver {
    type Error = Error;

    async fn create_node(&self, _node: &dyn graphiti_core::graph::Node) -> Result<()> {
        Ok(())
    }
    async fn get_node(&self, _id: &Uuid) -> Result<Option<Box<dyn graphiti_core::graph::Node>>> {
        Ok(None)
    }
    async fn update_node(&self, _node: &dyn graphiti_core::graph::Node) -> Result<()> {
        Ok(())
    }
    async fn delete_node(&self, _id: &Uuid) -> Result<()> {
        Ok(())
    }
    async fn create_edge(&self, _edge: &Edge) -> Result<()> {
        Ok(())
    }
    async fn get_edge_by_id(&self, _id: &Uuid) -> Result<Option<Edge>> {
        Ok(None)
    }
    async fn delete_edge_by_id(&self, _id: &Uuid) -> Result<bool> {
        Ok(false)
    }
    async fn get_edges(&self, _node_id: &Uuid, _direction: Direction) -> Result<Vec<Edge>> {
        Ok(Vec::new())
    }
    async fn get_all_nodes(&self) -> Result<Vec<Box<dyn graphiti_core::graph::Node>>> {
        Ok(Vec::new())
    }
    async fn get_all_edges(&self) -> Result<Vec<graphiti_core::graph::Edge>> {
        Ok(Vec::new())
    }
    async fn get_nodes_at_time(
        &self,
        _timestamp: chrono::DateTime<chrono::Utc>,
    ) -> Result<Vec<Box<dyn graphiti_core::graph::Node>>> {
        Ok(Vec::new())
    }
    async fn get_edges_at_time(
        &self,
        _timestamp: chrono::DateTime<chrono::Utc>,
    ) -> Result<Vec<graphiti_core::graph::Edge>> {
        Ok(Vec::new())
    }
    async fn get_node_history(
        &self,
        _node_id: &Uuid,
    ) -> Result<Vec<Box<dyn graphiti_core::graph::Node>>> {
        Ok(Vec::new())
    }
    async fn get_edge_history(&self, _edge_id: &Uuid) -> Result<Vec<graphiti_core::graph::Edge>> {
        Ok(Vec::new())
    }
}

#[cfg(all(test, feature = "backend-cozo", not(feature = "backend-sqlx")))]
mod tests {
    use super::*;
    use graphiti_core::graph::EpisodeType;

    #[tokio::test]
    async fn test_cozo_driver_creation() {
        let config = CozoConfig {
            engine: "mem".to_string(),
            path: "".to_string(),
            options: serde_json::json!({}),
        };

        let driver = CozoDriver::new(config).await;
        assert!(driver.is_ok());
    }

    #[tokio::test]
    async fn test_schema_initialization() {
        let config = CozoConfig {
            engine: "mem".to_string(),
            path: "".to_string(),
            options: serde_json::json!({}),
        };

        let driver = CozoDriver::new(config).await.unwrap();
        // 以插入与删除边的方式验证 schema
        let now = chrono::Utc::now();
        let edge = Edge {
            id: Uuid::new_v4(),
            source_id: Uuid::new_v4(),
            target_id: Uuid::new_v4(),
            relationship: "RELATES_TO".to_string(),
            properties: serde_json::json!({"fact": "A relates to B"}),
            temporal: TemporalMetadata {
                created_at: now,
                valid_from: now,
                valid_to: None,
                expired_at: None,
            },
            weight: 1.0,
        };
        driver.create_edge(&edge).await.unwrap();
        let deleted = driver.delete_edge_by_id(&edge.id).await.unwrap();
        assert!(deleted);
    }
}

#[cfg(all(test, feature = "backend-sqlx", not(feature = "backend-cozo")))]
mod tests_sqlite {
    use super::*;
    use chrono::Utc;

    #[tokio::test]
    async fn test_sqlite_edge_lifecycle() {
        let config = CozoConfig {
            engine: "sqlite".to_string(),
            path: ":memory:".to_string(),
            options: serde_json::json!({}),
        };

        let driver = CozoDriver::new(config).await.unwrap();

        let now = Utc::now();
        let edge = Edge {
            id: Uuid::new_v4(),
            source_id: Uuid::new_v4(),
            target_id: Uuid::new_v4(),
            relationship: "RELATES_TO".to_string(),
            properties: serde_json::json!({"fact": "A relates to B", "confidence": 0.9}),
            temporal: TemporalMetadata {
                created_at: now,
                valid_from: now,
                valid_to: None,
                expired_at: None,
            },
            weight: 1.0,
        };

        // create
        driver.create_edge(&edge).await.unwrap();

        // get
        let fetched = driver.get_edge_by_id(&edge.id).await.unwrap();
        assert!(fetched.is_some());
        let fetched = fetched.unwrap();
        assert_eq!(fetched.id, edge.id);
        assert_eq!(fetched.relationship, edge.relationship);
        assert_eq!(fetched.source_id, edge.source_id);
        assert_eq!(fetched.target_id, edge.target_id);

        // delete
        let deleted = driver.delete_edge_by_id(&edge.id).await.unwrap();
        assert!(deleted);

        // get again -> none
        let fetched2 = driver.get_edge_by_id(&edge.id).await.unwrap();
        assert!(fetched2.is_none());
    }
}

#[cfg(all(test, feature = "backend-cozo"))]
mod tests_cozo_mem {
    use super::*;
    use chrono::Utc;

    #[tokio::test]
    async fn test_cozo_mem_edge_lifecycle() {
        let config = CozoConfig {
            engine: "mem".to_string(),
            path: "".to_string(),
            options: serde_json::json!({}),
        };

        let driver = CozoDriver::new(config).await.unwrap();

        let now = Utc::now();
        let edge = Edge {
            id: Uuid::new_v4(),
            source_id: Uuid::new_v4(),
            target_id: Uuid::new_v4(),
            relationship: "RELATES_TO".to_string(),
            properties: serde_json::json!({"fact": "A relates to B", "key": "v"}),
            temporal: TemporalMetadata {
                created_at: now,
                valid_from: now,
                valid_to: None,
                expired_at: None,
            },
            weight: 0.7,
        };

        driver.create_edge(&edge).await.unwrap();
        let deleted = driver.delete_edge_by_id(&edge.id).await.unwrap();
        assert!(deleted);
    }
}
